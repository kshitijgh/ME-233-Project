# Define hyperparameters
learning_rate = 0.0001
batch_size = 64
num_epochs = 1000
regularization_term = 5e-3
Lp = 0.5

Epoch 1000/1000, Train Loss: 0.0122
Epoch 1000/1000, Train R2 Score: 0.3936
Test Loss MSE: 0.0112
R2 Score: 0.4847
Layer: input_layer.weight, Weights: tensor([[-4.7868e-05,  1.3697e-05, -3.3918e-01, -6.1131e-05, -2.1256e-05,
         -5.8782e-04,  3.0073e-05, -1.6857e-04, -1.7017e-04,  3.4730e-04,
          4.9596e-05, -1.1683e-04, -7.9242e-05,  1.8275e-05, -8.7895e-05,
          5.7308e-05,  2.0416e-04, -4.0819e-06,  1.6442e-04,  1.0603e-05,
         -1.0307e-04, -1.5477e-05, -1.7622e-04,  1.5851e-04,  1.8488e-05,
         -3.0782e-05, -3.2506e-05, -6.2513e-04, -1.1125e-04, -4.2724e-05,
         -7.2232e-05, -1.3046e-05,  5.5001e-05, -9.4561e-05]])

Number of Terms = 1
###############################################################################################################


# Define hyperparameters
learning_rate = 0.0001
batch_size = 64
num_epochs = 1000
regularization_term = 1e-3
Lp = 0.5

Epoch 1000/1000, Train Loss: 0.0085
Epoch 1000/1000, Train R2 Score: 0.5172
Test Loss MSE: 0.0082
R2 Score: 0.5694
Layer: input_layer.weight, Weights: tensor([[-1.8062e-04,  6.9943e-05, -4.5122e-01, -8.3501e-05,  1.4006e-04,
         -6.6419e-05, -4.7233e-05,  7.5944e-05,  6.1952e-05,  5.4912e-04,
          1.9226e-01, -7.9934e-05, -4.4031e-06,  3.8457e-05, -1.2816e-04,
          2.1734e-06,  7.5027e-05, -4.9722e-04, -5.2993e-05, -4.7863e-05,
          4.8626e-05,  3.7661e-05, -5.4326e-05, -9.0646e-04, -3.1842e-04,
          3.3964e-05, -1.6433e-04, -4.2984e-06,  2.0456e-05,  5.5820e-05,
          3.8168e-04,  1.0902e-04, -3.4740e-05, -8.5677e-04]])

Number of Terms = 2
###############################################################################################################


# Define hyperparameters
learning_rate = 0.0001
batch_size = 64
num_epochs = 2000                     ############ NOTE: High Number of Epochs
regularization_term = 5e-4
Lp = 0.5


Epoch 2000/2000, Train Loss: 0.0039
Epoch 2000/2000, Train R2 Score: 0.9397
Test Loss MSE: 0.0037
R2 Score: 0.9519
Layer: input_layer.weight, Weights: tensor([[ 6.8389e-01,  2.1122e-04, -1.4877e+00, -2.9546e-05,  2.4779e-05,
         -1.0960e-04, -3.0926e-05, -3.1663e-05, -1.2413e-04,  2.0867e-04,
          8.1172e-04,  4.1208e-05, -2.2406e-05,  3.8889e-05, -3.9083e-05,
         -2.5503e-05,  1.8208e-05,  2.7301e-06, -3.5978e-05,  8.8054e-04,
         -1.2765e-03, -3.9716e-05, -1.0107e-05,  2.4140e-04,  1.0918e-05,
         -1.7926e-05,  1.2862e-04,  1.1174e-04, -2.3453e-03,  2.1684e-03,
          2.2572e-05,  1.6197e-03, -1.1890e-04, -5.7659e-05]])

Number of Terms = 2
###############################################################################################################


# Define hyperparameters
learning_rate = 0.0001
batch_size = 64
num_epochs = 2000
regularization_term = 1e-4
Lp = 0.5

Epoch 2000/2000, Train Loss: 0.0009
Epoch 2000/2000, Train R2 Score: 0.9945
Test Loss MSE: 0.0009
R2 Score: 0.9950
Layer: input_layer.weight, Weights: tensor([[ 7.5927e-01,  7.4434e-05, -1.6851e+00, -3.7479e-05, -2.3885e-05,
          1.9312e-04,  3.6091e-05,  1.6600e-04, -2.9415e-05, -2.9806e-04,
          1.5214e-01,  3.2966e-06,  1.0239e-04, -1.1208e-04, -2.0711e-04,
          1.8601e-06, -6.9545e-06, -4.2678e-05, -1.6831e-05, -1.1971e-03,
          5.7473e-04,  6.9286e-05,  1.0896e-03,  7.3945e-04,  9.6353e-06,
          3.4667e-05,  2.1992e-04, -2.0279e-05,  1.2879e-05, -1.4316e-04,
          1.2838e-03,  1.5595e-04,  1.9121e-04, -1.3608e-03]])


Number of Terms = 3
###############################################################################################################


# Define hyperparameters
learning_rate = 0.0001
batch_size = 64
num_epochs = 2000
regularization_term = 5e-5
Lp = 0.5


Epoch 2000/2000, Train Loss: 0.0007
Epoch 2000/2000, Train R2 Score: 0.9961
Test Loss MSE: 0.0007
R2 Score: 0.9964
Layer: input_layer.weight, Weights: tensor([[ 6.7199e-01,  1.9688e-03, -1.1026e+00,  5.0401e-05,  9.7326e-05,
         -1.4753e-01,  1.3915e-05, -8.3311e-01,  7.8577e-06,  4.5007e-04,
         -7.8704e-05,  1.1733e-05, -4.6377e-05,  3.7421e-05,  1.4394e-03,
         -1.9652e-05,  6.9002e-04, -1.0255e-04,  5.1408e-05, -3.8775e-05,
         -7.8320e-06,  2.7330e-05,  5.1134e-05, -1.8652e-04, -9.6395e-06,
          3.4026e-05,  4.7902e-06,  1.9177e-04,  2.1773e-05,  4.7971e-05,
         -2.6660e-05, -1.0589e-04,  3.7037e-05,  2.7475e-04]])


Number of Terms = 4
###############################################################################################################

# Define hyperparameters
learning_rate = 0.0001
batch_size = 64
num_epochs = 1000
regularization_term = 1e-5
Lp = 0.5

Epoch 1000/1000, Train Loss: 0.0002
Epoch 1000/1000, Train R2 Score: 0.9993
Test Loss MSE: 0.0002
R2 Score: 0.9995
Layer: input_layer.weight, Weights: tensor([[ 4.5948e-01,  1.0465e-05, -5.9498e-01,  1.6697e-04, -9.1094e-05,
         -5.1334e-01,  1.6242e-03, -5.5257e-01,  1.2956e-03, -5.3496e-05,
          1.2188e-01,  1.4118e-04, -7.2277e-04,  1.6485e-05, -4.0595e-05,
          3.6383e-04, -6.0934e-01, -7.0573e-05, -4.9445e-05,  1.1422e-06,
          1.9302e-04,  6.5155e-05,  5.8520e-05, -1.9335e-04, -1.9985e-05,
          1.0981e-05, -2.3680e-04, -2.3644e-05,  9.8399e-05, -1.0329e-04,
         -3.7441e-05,  8.2147e-06, -3.5302e-04, -2.7471e-03]])

Number of Terms = 6
###############################################################################################################


# Define hyperparameters
learning_rate = 0.0001
batch_size = 64
num_epochs = 1000
regularization_term = 5e-6
Lp = 0.5

Epoch 1000/1000, Train Loss: 0.0001
Epoch 1000/1000, Train R2 Score: 0.9993
Test Loss MSE: 0.0001
R2 Score: 0.9994
Layer: input_layer.weight, Weights: tensor([[ 4.6215e-01, -8.9772e-04, -5.7734e-01, -5.9100e-04,  8.8920e-05,
         -4.2584e-01, -1.0643e-01, -5.6535e-01,  2.1535e-05,  1.4177e-03,
          2.2048e-01, -1.9748e-04, -3.5088e-05, -7.1591e-04, -1.6157e-05,
         -8.2979e-04, -6.6034e-01,  5.8899e-05, -1.0944e-04,  1.7222e-04,
          4.4551e-04,  5.9373e-05,  2.7745e-04,  1.9986e-04,  5.6655e-04,
         -2.7528e-05,  4.9703e-04, -1.0026e-04,  7.3772e-06,  6.2755e-05,
          3.8839e-05, -6.4911e-05,  1.0924e-04, -4.4990e-04]])


Number of Terms = 7
###############################################################################################################


# Define hyperparameters
learning_rate = 0.0001
batch_size = 64
num_epochs = 1000
regularization_term = 1e-6
Lp = 0.5



Epoch 1000/1000, Train Loss: 0.0001
Epoch 1000/1000, Train R2 Score: 0.9994
Test Loss MSE: 0.0001
R2 Score: 0.9994
Layer: input_layer.weight, Weights: tensor([[ 4.3262e-01,  3.3209e-05, -4.8697e-01, -2.4954e-01, -6.3244e-02,
         -1.7382e-01, -1.3776e-01, -4.8745e-01, -7.1019e-05, -2.3692e-01,
          4.3487e-01,  1.1063e-04,  3.3468e-02,  7.5935e-05,  4.5002e-04,
         -4.0627e-06, -5.4867e-01,  7.4984e-04, -6.1876e-02,  7.6421e-05,
         -1.5880e-05, -9.3720e-05, -9.6049e-02, -3.6907e-05,  5.2313e-05,
         -2.3483e-03, -8.4571e-05,  4.3412e-04,  5.4532e-05,  6.3922e-04,
         -6.1531e-04, -1.1145e-02,  1.7451e-03, -1.2919e-06]])


Number of Terms = 14
###############################################################################################################